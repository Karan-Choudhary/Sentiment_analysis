{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Dropout\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for loading the data\n",
    "class LoadData:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "\n",
    "    def load_data(self):\n",
    "        data = pd.read_csv(self.path)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for preprocessing the data\n",
    "class PreprocessData:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        # initliaze the X and y\n",
    "        self.X_final = None\n",
    "        self.y_final = None\n",
    "        nltk.download('stopwords')\n",
    "    \n",
    "    def splitting(data):\n",
    "        data['label'] = data['airline_sentiment'].map({'positive':1, 'negative':0})\n",
    "        X = data['text']\n",
    "        y = data['label']\n",
    "        return X, y\n",
    "    \n",
    "    def preprocessing(self):\n",
    "        voc_size = 5000\n",
    "        \n",
    "        X, y = PreprocessData.splitting(self.data)\n",
    "        \n",
    "        messages = X.copy()\n",
    "        ps = PorterStemmer()\n",
    "        corpus = []\n",
    "        \n",
    "        for i in range(0, len(messages)):\n",
    "            review = re.sub('[^a-zA-Z]', ' ', messages[i])\n",
    "            review = review.lower()\n",
    "            review = review.split()\n",
    "            \n",
    "            review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "            review = ' '.join(review)\n",
    "            corpus.append(review)\n",
    "            \n",
    "        onehot_repr = [one_hot(words, voc_size) for words in corpus]\n",
    "        \n",
    "        sent_length = 20\n",
    "        embedded_docs = pad_sequences(onehot_repr, padding='pre', maxlen=sent_length)\n",
    "        \n",
    "        self.X_final = np.array(embedded_docs)\n",
    "        self.y_final = np.array(y)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X_final, self.y_final, test_size=0.2, random_state=42)\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model class\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "    def create_model(self):\n",
    "        embedding_vector_features = 40\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(5000, embedding_vector_features, input_length=20))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Bidirectional(LSTM(100)))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        self.model = model\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat a class for training the model which inherits from the model class\n",
    "class TrainModel(Model):\n",
    "    def __init__(self, X_train, X_test, y_train, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        super().__init__()\n",
    "        \n",
    "    def train_model(self):\n",
    "        model = TrainModel.create_model(self)\n",
    "        model.fit(self.X_train, self.y_train, validation_data=(self.X_test, self.y_test), epochs=5, batch_size=64)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for evaluating the model\n",
    "class EvaluateModel:\n",
    "    def __init__(self, model, X_test, y_test):\n",
    "        self.model = model\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def evaluate_model(self):\n",
    "        y_pred = (self.model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        print(cm)\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "        print(accuracy_score(self.y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement inference class\n",
    "class Inference:\n",
    "    def __init__(self, model, X_test):\n",
    "        self.model = model\n",
    "        self.X_test = X_test\n",
    "        \n",
    "    def predict(self):\n",
    "        y_pred = (self.model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 1s 7ms/step\n",
      "[[1768   94]\n",
      " [ 140  307]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1862\n",
      "           1       0.77      0.69      0.72       447\n",
      "\n",
      "    accuracy                           0.90      2309\n",
      "   macro avg       0.85      0.82      0.83      2309\n",
      "weighted avg       0.90      0.90      0.90      2309\n",
      "\n",
      "0.8986574274577739\n",
      "73/73 [==============================] - 1s 7ms/step\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# call the classes\n",
    "if __name__ == '__main__':\n",
    "    data = LoadData('data/airline_sentiment_analysis.csv')\n",
    "    data = data.load_data()\n",
    "    \n",
    "    preprocess = PreprocessData(data)\n",
    "    X_train, X_test, y_train, y_test = preprocess.preprocessing()\n",
    "    \n",
    "    train = TrainModel(X_train, X_test, y_train, y_test)\n",
    "    model = train.train_model()\n",
    "    \n",
    "    evaluate = EvaluateModel(model, X_test, y_test)\n",
    "    evaluate.evaluate_model()\n",
    "    \n",
    "    inference = Inference(model, X_test)\n",
    "    y_pred = inference.predict()\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
